{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海市', '市级', '科技', '重大', '专项', '》']\n",
      "['上海市', '国家级', '科研', '重大', '项目']\n"
     ]
    }
   ],
   "source": [
    "from ltp import LTP\r\n",
    "ltp = LTP()\r\n",
    "\r\n",
    "sentence1 = '上海市市级科技重大专项》'\r\n",
    "sentence2= '上海市国家级科研重大项目'\r\n",
    "\r\n",
    "segment1 = ltp.seg([sentence1])[0][0]\r\n",
    "segment2 = ltp.seg([sentence2])[0][0]\r\n",
    "print(segment1)\r\n",
    "print(segment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.25"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(text1, text2):\r\n",
    "    intersection = set(segment1)&set(segment2)\r\n",
    "    union = set(segment1)|set(segment2)\r\n",
    "    result = len(intersection)/len(union)\r\n",
    "    return result\r\n",
    "\r\n",
    "segment1 = ['上海市', '市级', '科技', '重大', '专项']\r\n",
    "segment2 = ['上海市','国家级', '科研', '重大', '项目']\r\n",
    "jaccard(segment1, segment2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The degree of inclusion of text 2 in text 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015年', '8月', '3日', '，', '信永中和', '出具', '《', '验资', '报告', '》', '（', 'XYZH', '[', '20l5]NJA30092', '号', '）', '，', '对', '鸿基', '有限', '整体', '变更', '为', '股份公司', '的', '出资', '情况', '进行', '了', '验资', '确认', '。']\n",
      "['《', '验资', '报告', '》', '（', 'XYZH', '[', '20l5]NJA30092', '号', '）']\n",
      "1.0\n",
      "2015年8月3日，信永中和出具《验资报告》（XYZH[20l5]NJA30092号）\n"
     ]
    }
   ],
   "source": [
    "class Lexical_analysis:\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def inclusion_rate(left_segment, right_segment):\r\n",
    "\r\n",
    "        '''\r\n",
    "        Calculate the inclusion degree of the intersection of left segment and right segment in right segment\r\n",
    "\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        input: left_segment, right_segment\r\n",
    "        Returns\r\n",
    "        ----------\r\n",
    "        similarity: float\r\n",
    "        '''\r\n",
    "        intersection = set(left_segment) & set(right_segment)\r\n",
    "        similarity = len(intersection) / len(set(right_segment))\r\n",
    "        return similarity\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def get_search_str(left_segment, right_segment, left_sentence):\r\n",
    "        '''\r\n",
    "        find the serach string that use for add footnote in left_sentence \r\n",
    "\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        input: left_segment, right_segment\r\n",
    "        Returns\r\n",
    "        ----------\r\n",
    "        search_str: string\r\n",
    "        '''    \r\n",
    "        intersection = set(left_segment) & set(right_segment)\r\n",
    "        # The word with the largest index in left_segment\r\n",
    "        position_word = left_segment[max([left_segment.index(word) for word in list(intersection)])]\r\n",
    "        # An index of the concluding words in left_segment\r\n",
    "        index = left_sentence.rfind(position_word) + len(position_word)-1\r\n",
    "        if (index+1) < len(left_sentence):\r\n",
    "            if left_sentence[index+1] in '》”’）':\r\n",
    "                search_str = left_sentence[:index+2]\r\n",
    "            else:\r\n",
    "                search_str = left_sentence[:index+1]\r\n",
    "        else:\r\n",
    "            search_str = left_sentence[:index+1]\r\n",
    "        return search_str \r\n",
    "\r\n",
    "class Dependency_Parser:\r\n",
    "    pass\r\n",
    "\r\n",
    "if __name__==\"__main__\":\r\n",
    "\r\n",
    "    left_sentence = '2015年8月3日，信永中和出具《验资报告》（XYZH[20l5]NJA30092号），对鸿基有限整体变更为股份公司的出资情况进行了验资确认。'\r\n",
    "    right_sentence= '《验资报告》（XYZH[20l5]NJA30092号）'\r\n",
    "\r\n",
    "\r\n",
    "    from ltp import LTP\r\n",
    "    ltp = LTP()\r\n",
    "\r\n",
    "    left_segment = ltp.seg([left_sentence])[0][0]\r\n",
    "    right_segment = ltp.seg([right_sentence])[0][0]\r\n",
    "    print(left_segment)\r\n",
    "    print(right_segment)\r\n",
    "\r\n",
    "    similarity = Lexical_analysis.inclusion_rate(left_segment, right_segment)\r\n",
    "    print(similarity)\r\n",
    "\r\n",
    "    search_str = Lexical_analysis.get_search_str(left_segment, right_segment, left_sentence)\r\n",
    "    print(search_str)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('发行人', '江苏鸿基节能新技术股份有限公司'),\n",
       " ('发行人', '鸿基节能'),\n",
       " ('江苏鸿基节能新技术股份有限公司', '发行人'),\n",
       " ('江苏鸿基节能新技术股份有限公司', '鸿基节能'),\n",
       " ('鸿基节能', '发行人'),\n",
       " ('鸿基节能', '江苏鸿基节能新技术股份有限公司')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "full_name = '江苏鸿基节能新技术股份有限公司'\n",
    "short_name = '鸿基节能'\n",
    "\n",
    "iter = permutations(['发行人', full_name, short_name], 2)\n",
    "list(iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_company_name(left_sentence, right_sentence):\n",
    "    if '发行人' in right_sentence and full_name in left_sentence:\n",
    "        right_sentence = right_sentence.replace('发行人', full_name)\n",
    "    elif '发行人' in right_sentence and short_name  in left_sentence:\n",
    "        right_sentence = right_sentence.replace('发行人', short_name)\n",
    "    elif full_name in right_sentence and '发行人'  in left_sentence:\n",
    "        right_sentence = right_sentence.replace(full_name, '发行人')\n",
    "    elif full_name in right_sentence and short_name in left_sentence:\n",
    "        right_sentence = right_sentence.replace(full_name, short_name)\n",
    "    elif short_name in right_sentence and '发行人' in left_sentence:\n",
    "        right_sentence = right_sentence.replace(short_name, '发行人')\n",
    "    elif short_name in right_sentence and full_name in left_sentence:\n",
    "        right_sentence = right_sentence.replace(short_name, full_name)\n",
    "    else:\n",
    "        right_sentence = right_sentence\n",
    "    return right_sentence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
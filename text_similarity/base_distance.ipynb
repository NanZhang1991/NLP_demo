{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海市', '市级', '科技', '重大', '专项', '》']\n",
      "['上海市', '国家级', '科研', '重大', '项目']\n"
     ]
    }
   ],
   "source": [
    "from ltp import LTP\r\n",
    "ltp = LTP()\r\n",
    "\r\n",
    "sentence1 = '上海市市级科技重大专项》'\r\n",
    "sentence2= '上海市国家级科研重大项目'\r\n",
    "\r\n",
    "segment1 = ltp.seg([sentence1])[0][0]\r\n",
    "segment2 = ltp.seg([sentence2])[0][0]\r\n",
    "print(segment1)\r\n",
    "print(segment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.25"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(text1, text2):\r\n",
    "    intersection = set(segment1)&set(segment2)\r\n",
    "    union = set(segment1)|set(segment2)\r\n",
    "    result = len(intersection)/len(union)\r\n",
    "    return result\r\n",
    "\r\n",
    "segment1 = ['上海市', '市级', '科技', '重大', '专项']\r\n",
    "segment2 = ['上海市','国家级', '科研', '重大', '项目']\r\n",
    "jaccard(segment1, segment2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The degree of inclusion of text 2 in text 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "《市级科技重大专项上海市》\n",
      "上海市市级科技重大项目\n"
     ]
    }
   ],
   "source": [
    "class Lexical_analysis:\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def inclusion_rate(left_segment, right_segment):\r\n",
    "\r\n",
    "        '''\r\n",
    "        Calculate the inclusion degree of the intersection of left segment and right segment in right segment\r\n",
    "\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        input: left_segment, right_segment\r\n",
    "        Returns\r\n",
    "        ----------\r\n",
    "        similarity: float\r\n",
    "        '''\r\n",
    "        intersection = set(left_segment) & set(right_segment)\r\n",
    "        similarity = len(intersection) / len(set(right_segment))\r\n",
    "        return similarity\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def get_search_str(left_segment, right_segment, left_sentence):\r\n",
    "        '''\r\n",
    "        find the serach string that use for add footnote in left_sentence \r\n",
    "\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        input: left_segment, right_segment\r\n",
    "        Returns\r\n",
    "        ----------\r\n",
    "        search_str: string\r\n",
    "        '''    \r\n",
    "        intersection = set(left_segment) & set(right_segment)\r\n",
    "        # The word with the largest index in left_segment\r\n",
    "        position_word = left_segment[max([left_segment.index(word) for word in list(intersection)])]\r\n",
    "        # An index of the concluding words in left_segment\r\n",
    "        index = left_sentence.rfind(position_word) + len(position_word)-1\r\n",
    "        if (index+1) < len(left_sentence):\r\n",
    "            if left_sentence[index+1] in '》”’':\r\n",
    "                search_str = left_sentence[:index+2]\r\n",
    "        else:\r\n",
    "            search_str = left_sentence[:index+1]\r\n",
    "        return search_str \r\n",
    "\r\n",
    "class Dependency_Parser:\r\n",
    "    pass\r\n",
    "\r\n",
    "if __name__==\"__main__\":\r\n",
    "\r\n",
    "    left_sentence = '《市级科技重大专项上海市》黄埔区'\r\n",
    "    left_sentence2= '上海市市级科技重大项目'\r\n",
    "    right_sentence= '上海市国家级科研重大项目'\r\n",
    "\r\n",
    "    left_segment = ['市级', '科技', '重大', '专项','上海市',]\r\n",
    "    left_segment2 = ['上海市', '市级', '科技', '重大', '项目']\r\n",
    "    right_segment = ['上海市','国家级', '科研', '重大', '项目']\r\n",
    "\r\n",
    "    similarity = Lexical_analysis.inclusion_rate(left_segment, right_segment)\r\n",
    "    print(similarity)\r\n",
    "\r\n",
    "    search_str = Lexical_analysis.get_search_str(left_segment, right_segment, left_sentence)\r\n",
    "    print(search_str)\r\n",
    "\r\n",
    "    search_str = Lexical_analysis.get_search_str(left_segment2, right_segment, left_sentence2)\r\n",
    "    print(search_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('py3.7': conda)",
   "metadata": {
    "interpreter": {
     "hash": "37def44e3045786e2faeb86ea99d99641ffb6cda7629f9968e635f86f51987d0"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
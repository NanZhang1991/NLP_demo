{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:316184)",
      "at w.execute (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:315573)",
      "at w.start (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:311378)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325786)",
      "at async t.CellExecutionQueue.start (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325326)"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from ast import literal_eval\n",
    "from transformers import BertTokenizer,  BertConfig, TFBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集整理\r\n",
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_zip(file_name):  \n",
    "    \"\"\"unzip zip file\"\"\"  \n",
    "    zip_file = zipfile.ZipFile(file_name)\n",
    "    for name in zip_file.namelist():  \n",
    "        zip_file.extract(name,'../data')\n",
    "    zip_file.close()\n",
    "    dir_path = file_name.rsplit('.', 1)[0]\n",
    "    return dir_path\n",
    "\n",
    "def json_to_df(path, nrows=False):\n",
    "    if nrows:\n",
    "        df = pd.read_json(path, nrows=nrows, lines=True)\n",
    "    else:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "    df = df[['text', 'spo_list']]\n",
    "    return df\n",
    "\n",
    "def merge_df(path):\n",
    "    if path.rsplit('.', 1)[1]=='zip':\n",
    "        dir_path = un_zip(path)\n",
    "    else:\n",
    "        dir_path = path\n",
    "    total_df = pd.DataFrame()\n",
    "    for fn in os.listdir(dir_path):\n",
    "        df = json_to_df(os.path.join(dir_path, fn))\n",
    "        df_fn = fn[:fn.rfind('.')]\n",
    "        df.insert(0, 'fn', df_fn)\n",
    "        total_df =  total_df.append(df)\n",
    "    total_df.reset_index(drop=True, inplace=True)\n",
    "    print(f'original data size: {total_df.shape}') #\n",
    "    print(f'original data sample: {df.sample(5)}')\n",
    "    return total_df   \n",
    "\n",
    "def read_schemads(path_or_df):\n",
    "    if not isinstance(path_or_df, pd.DataFrame):\n",
    "        print(1)\n",
    "        schemads_path = path_or_df\n",
    "        predicate_data = pd.read_json(schemads_path, lines=True)\n",
    "        id2p = predicate_data['predicate'].drop_duplicates().reset_index(drop=True).to_dict()\n",
    "    else:\n",
    "        df = path_or_df\n",
    "        id2p = df['spo_list'].apply(lambda spo_list: [spo['predicate'] for spo in spo_list])\n",
    "        id2p = id2p.explode().drop_duplicates().reset_index(drop=True).to_dict()\n",
    "    p2id = dict(zip(id2p.values(), id2p.keys()))\n",
    "    print(f'length of p2id :{len(p2id)}')#\n",
    "    print(f'random p2id sample:{random.sample(p2id.items(), 5)}')#\n",
    "    return id2p, p2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 百度三元组关系数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path ='../data/百度关系抽取数据集/train_data.json'\r\n",
    "# train_data = json_to_df(train_path, nrows=10000)\r\n",
    "# print(f'Train data size: {train_data.shape}') #\r\n",
    "\r\n",
    "# dev_path = '../data/百度关系抽取数据集/dev_data.json'\r\n",
    "# dev_data = json_to_df(dev_path, nrows=5000)\r\n",
    "# print(f'Validation data size: {dev_data.shape}') \r\n",
    "\r\n",
    "# schemads_path = '../data/百度关系抽取数据集/all_50_schemas'\r\n",
    "# id2p, p2id = read_schemads(schemads_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 招股说明书三元组数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data size: (10698, 3)\n",
      "original data sample:                                       fn  \\\n",
      "102  白银有色首次公开发行股票招股说明书_601212_20170112_1   \n",
      "71   白银有色首次公开发行股票招股说明书_601212_20170112_1   \n",
      "101  白银有色首次公开发行股票招股说明书_601212_20170112_1   \n",
      "8    白银有色首次公开发行股票招股说明书_601212_20170112_1   \n",
      "166  白银有色首次公开发行股票招股说明书_601212_20170112_1   \n",
      "\n",
      "                                                  text  \\\n",
      "102  2014年末，公司对红鹭矿业公司的其他应收款账面余额为13,855.28万元，全部为对红鹭矿...   \n",
      "71   2016年3月17日,江西高院开庭审理本案，原告民生银行南昌分行变更诉讼请求，要求江西地方公...   \n",
      "101  2013年5月，中联评估出具了中联评报字【2013】第447号《资产评估报告》。本次评估采用...   \n",
      "8    2011年7月14日，本公司全资子公司贵金属公司在英属维尔京群岛设立BCX公司，注册资本1美...   \n",
      "166  中信集团持有国安集团20.945%的股权，是国安集团的第一大股东。中信集团和国安集团属于一致...   \n",
      "\n",
      "                                              spo_list  \n",
      "102  [{'predicate': '应收账款余额', 'object_type': '金额', ...  \n",
      "71   [{'predicate': '应付票据', 'object_type': '金额', 's...  \n",
      "101  [{'predicate': '出具日期', 'object_type': '日期', 's...  \n",
      "8    [{'predicate': '注册资本', 'object_type': '金额', 's...  \n",
      "166  [{'predicate': '关联方', 'object_type': '公司', 'su...  \n",
      "original data size: (837, 3)\n",
      "original data sample:       fn                                               text  \\\n",
      "138  科沃斯  截至2015年12月31日、2016年12月31日和2017年12月31日，公司的预付款项分...   \n",
      "146  科沃斯  截至2015年12月31日、2016年12月31日和2017年12月31日，公司预收款项余额...   \n",
      "150  科沃斯  2015年度、2016年度和2017年度公司的销售费用分别为36,999.49万元、51,9...   \n",
      "134  科沃斯    8、本公司之子公司EcovacsGermany于2017年10月31日设立子公司Ecovacs   \n",
      "5    科沃斯  1999年3月26日，江苏苏州兴联会计师事务所出具《验资报告》（苏兴会园字[1999]第12...   \n",
      "\n",
      "                                              spo_list  \n",
      "138  [{'predicate': '预付款项', 'object_type': '金额', 's...  \n",
      "146  [{'predicate': '预收款项余额', 'object_type': '金额', ...  \n",
      "150  [{'predicate': '销售费用', 'object_type': '金额', 's...  \n",
      "134  [{'predicate': '成立日期', 'object_type': '公司', 's...  \n",
      "5    [{'predicate': '出具日期', 'object_type': '文件', 's...  \n",
      "length of p2id :145\n",
      "random p2id sample:[('预收款项', 32), ('固定资产账面价值', 121), ('应付账款余额', 128), ('应收票据', 66), ('其他成本', 80)]\n"
     ]
    }
   ],
   "source": [
    "path1 = '../data/招股说明书三元组数据集_云测标注.zip'\n",
    "df1 = merge_df(path1)\n",
    "\n",
    "path2 = '../data/招股说明书三元组数据集_内部标注'\n",
    "df2 = merge_df(path2)\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "id2p, p2id = read_schemads(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spo(spo_list):\r\n",
    "    for spo in spo_list:\r\n",
    "        spo['predicate'] = spo['predicate'].lower()\r\n",
    "        spo['subject'] = spo['subject'].lower()\r\n",
    "        spo['object'] = spo['object'].lower()\r\n",
    "    return spo_list\r\n",
    "\r\n",
    "def data_clean(df):\r\n",
    "    df.dropna(how='any', inplace=True)\r\n",
    "    df = df[df['spo_list'].apply(lambda x: len(x)>0)]\r\n",
    "    df.drop_duplicates(subset=['text'], inplace=True)\r\n",
    "    df.reset_index(drop=True, inplace=True)\r\n",
    "    df['text'] = df['text'].str.lower()\r\n",
    "    df['spo_list'] = df['spo_list'].apply(clean_spo)\r\n",
    "    print(f'Real data size is {df.shape[0]}')\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data size is 9263\n"
     ]
    }
   ],
   "source": [
    "df = data_clean(df)\r\n",
    "# train_data = data_clean(train_data)\r\n",
    "# dev_data = data_clean(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (9263, 3)\n",
      "Validation data size: (9263, 3)\n",
      "spo_count 25937\n"
     ]
    }
   ],
   "source": [
    "train_size=0.9\r\n",
    "\r\n",
    "# train_data = df.sample(frac=train_size,random_state=200)\r\n",
    "# dev_data = df.drop(train_data.index)\r\n",
    "train_data = df\r\n",
    "dev_data = df \r\n",
    "dev_data.reset_index(drop=True, inplace=True)\r\n",
    "train_data.reset_index(drop=True, inplace=True)\r\n",
    "print(f'Train data size: {train_data.shape}') #\r\n",
    "print(f'Validation data size: {dev_data.shape}') \r\n",
    "\r\n",
    "spo_single_count = df['spo_list'].apply(lambda x: len(x))\r\n",
    "spo_count = spo_single_count.sum()\r\n",
    "print('spo_count', spo_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_data['text'].to_list()\r\n",
    "train_spo = train_data['spo_list'].to_list()\r\n",
    "\r\n",
    "\r\n",
    "dev_text = dev_data['text'].to_list()\r\n",
    "dev_spo = dev_data['spo_list'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签集分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    货币资金-日期-金额\n",
      "1    资本公积-日期-金额\n",
      "2    任职日期-人物-日期\n",
      "3    任职日期-人物-日期\n",
      "4     研究生-人物-学历\n",
      "Name: spo_list, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='spo_list'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 2160x1080 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "dataset_name = '招股说明书'\r\n",
    "spo = df['spo_list'].explode().reset_index(drop=True)\r\n",
    "spo_group = spo.apply(lambda x: '-'.join([x['predicate'] , x['subject_type'], x['object_type']]))\r\n",
    "print(spo_group.head())\r\n",
    "spo_group_count = spo_group.groupby(spo_group).count()\r\n",
    "spo_group_count.to_csv('../data/' + dataset_name + '_spo_group_count.csv', encoding='utf_8_sig')\r\n",
    "spo_group_count.plot(kind='bar', figsize=(30,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_data(text_list, spo_list, p2id, tokenizer, MAX_LEN, spo_count):\r\n",
    "    id_label = {}\r\n",
    "    ct = len(text_list)\r\n",
    "    MAX_LEN = MAX_LEN\r\n",
    "    input_ids = np.zeros((spo_count,MAX_LEN),dtype='int32')\r\n",
    "    attention_mask = np.zeros((spo_count,MAX_LEN),dtype='int32')\r\n",
    "    start_tokens = np.zeros((spo_count,MAX_LEN),dtype='int32')\r\n",
    "    end_tokens = np.zeros((spo_count,MAX_LEN),dtype='int32')\r\n",
    "    send_s_po = np.zeros((spo_count,2),dtype='int32')\r\n",
    "    object_start_tokens = np.zeros((spo_count,MAX_LEN,len(p2id)),dtype='int32')\r\n",
    "    object_end_tokens = np.zeros((spo_count,MAX_LEN,len(p2id)),dtype='int32')\r\n",
    "    index_vaild = -1\r\n",
    "    for k in range(ct):\r\n",
    "        context_k = text_list[k].lower().replace(' ','')\r\n",
    "        enc_context = tokenizer.encode(context_k,max_length=MAX_LEN,truncation=True)      \r\n",
    "        start = []\r\n",
    "        S_index = []\r\n",
    "        for j in range(len(spo_list[k])):\r\n",
    "            answers_text_k = spo_list[k][j]['subject'].lower().replace(' ','')\r\n",
    "            chars = np.zeros((len(context_k)))\r\n",
    "            index = context_k.find(answers_text_k)\r\n",
    "            chars[index:index+len(answers_text_k)]=1\r\n",
    "            offsets = []\r\n",
    "            idx=0\r\n",
    "            for t in enc_context[1:]:\r\n",
    "                w = tokenizer.decode([t])\r\n",
    "                if '#' in w and len(w)>1:\r\n",
    "                    w = w.replace('#','')\r\n",
    "                if w == '[UNK]':\r\n",
    "                    w = '。'\r\n",
    "                offsets.append((idx,idx+len(w)))\r\n",
    "                idx += len(w)\r\n",
    "            toks = []\r\n",
    "            for i,(a,b) in enumerate(offsets):\r\n",
    "                sm = np.sum(chars[a:b])\r\n",
    "                if sm>0: \r\n",
    "                    toks.append(i) \r\n",
    "            if len(toks)>0:\r\n",
    "                S_start = toks[0]+1\r\n",
    "                S_end = toks[-1]+1\r\n",
    "                if (S_start,S_end) not in start:\r\n",
    "                    index_vaild += 1\r\n",
    "                    start.append((S_start,S_end))\r\n",
    "                    input_ids[index_vaild,:len(enc_context)] = enc_context\r\n",
    "                    attention_mask[index_vaild,:len(enc_context)] = 1\r\n",
    "                    start_tokens[index_vaild,S_start] = 1\r\n",
    "                    end_tokens[index_vaild,S_end] = 1\r\n",
    "                    send_s_po[index_vaild,0] = S_start\r\n",
    "                    send_s_po[index_vaild,1] = S_end\r\n",
    "                    S_index.append([j,index_vaild])\r\n",
    "                else:\r\n",
    "                    S_index.append([j,index_vaild])\r\n",
    "        if len(S_index) > 0:\r\n",
    "            for index_ in range(len(S_index)):\r\n",
    "                #随机选取object的首位，如果选取错误，则作为负样本\r\n",
    "                object_text_k = spo_list[k][S_index[index_][0]]['object'].lower().replace(' ','')\r\n",
    "                predicate = spo_list[k][S_index[index_][0]]['predicate']\r\n",
    "                p_id = p2id[predicate]\r\n",
    "                chars = np.zeros((len(context_k)))\r\n",
    "                index = context_k.find(object_text_k)\r\n",
    "                chars[index:index+len(object_text_k)]=1\r\n",
    "                offsets = [] \r\n",
    "                idx = 0\r\n",
    "                for t in enc_context[1:]:\r\n",
    "                    w = tokenizer.decode([t])\r\n",
    "                    if '#' in w and len(w)>1:\r\n",
    "                        w = w.replace('#','')\r\n",
    "                    if w == '[UNK]':\r\n",
    "                        w = '。'\r\n",
    "                    offsets.append((idx,idx+len(w)))\r\n",
    "                    idx += len(w)\r\n",
    "                toks = []\r\n",
    "                for i,(a,b) in enumerate(offsets):\r\n",
    "                    sm = np.sum(chars[a:b])\r\n",
    "                    if sm>0: \r\n",
    "                        toks.append(i) \r\n",
    "                if len(toks)>0:\r\n",
    "                    id_label[p_id] = predicate\r\n",
    "                    P_start = toks[0]+1\r\n",
    "                    P_end = toks[-1]+1\r\n",
    "                    object_start_tokens[S_index[index_][1]][P_start,p_id] = 1\r\n",
    "                    object_end_tokens[S_index[index_][1]][P_end,p_id] = 1\r\n",
    "    return input_ids[:index_vaild], attention_mask[:index_vaild], start_tokens[:index_vaild], end_tokens[:index_vaild], send_s_po[:index_vaild], \\\r\n",
    "           object_start_tokens[:index_vaild], object_end_tokens[:index_vaild], id_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_length = 256  \n",
    "model_path = '../model_dirs/bert-base-chinese'  \n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "input_ids, attention_mask, start_tokens, end_tokens, send_s_po, object_start_tokens, object_end_tokens, id_label \\\n",
    "= proceed_data(train_text, train_spo, p2id, tokenizer, max_length, spo_count)\n",
    "\n",
    "print(start_tokens.shape)\n",
    "\n",
    "val_inputs = tokenizer(dev_text, max_length=max_length, padding='max_length', truncation=True, return_tensors='tf') \n",
    "val_input_ids, val_attention_mask = val_inputs['input_ids'], val_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15605, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 1.09 s, total: 1min 32s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "def new_loss(true,pred):\r\n",
    "    true = tf.cast(true,tf.float32)\r\n",
    "    loss = K.sum(K.binary_crossentropy(true, pred))\r\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(tf.keras.layers.Layer):\r\n",
    "    \"\"\"(Conditional) Layer Normalization\r\n",
    "    hidden_*系列参数仅为有条件输入时(conditional=True)使用\r\n",
    "    \"\"\"\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        center=True,\r\n",
    "        scale=True,\r\n",
    "        epsilon=None,\r\n",
    "        conditional=False,\r\n",
    "        hidden_units=None,\r\n",
    "        hidden_activation='linear',\r\n",
    "        hidden_initializer='glorot_uniform',\r\n",
    "        **kwargs):\r\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\r\n",
    "        self.center = center\r\n",
    "        self.scale = scale\r\n",
    "        self.conditional = conditional\r\n",
    "        self.hidden_units = hidden_units\r\n",
    "        self.hidden_activation = tf.keras.activations.get(hidden_activation)\r\n",
    "        self.hidden_initializer = tf.keras.initializers.get(hidden_initializer)\r\n",
    "        self.epsilon = epsilon or 1e-12\r\n",
    "        \r\n",
    "    def compute_mask(self, inputs, mask=None):\r\n",
    "        if self.conditional:\r\n",
    "            masks = mask if mask is not None else []\r\n",
    "            masks = [m[None] for m in masks if m is not None]\r\n",
    "            if len(masks) == 0:\r\n",
    "                return None\r\n",
    "            else:\r\n",
    "                return K.all(K.concatenate(masks, axis=0), axis=0)\r\n",
    "        else:\r\n",
    "            return mask\r\n",
    "        \r\n",
    "    def build(self, input_shape):\r\n",
    "        super(LayerNormalization, self).build(input_shape)\r\n",
    "        if self.conditional:\r\n",
    "            shape = (input_shape[0][-1],)\r\n",
    "        else:\r\n",
    "            shape = (input_shape[-1],)\r\n",
    "        if self.center:\r\n",
    "            self.beta = self.add_weight(\r\n",
    "                shape=shape, initializer='zeros', name='beta')\r\n",
    "        if self.scale:\r\n",
    "            self.gamma = self.add_weight(\r\n",
    "                shape=shape, initializer='ones', name='gamma')\r\n",
    "        if self.conditional:\r\n",
    "            if self.hidden_units is not None:\r\n",
    "                self.hidden_dense = tf.keras.layers.Dense(\r\n",
    "                    units=self.hidden_units,\r\n",
    "                    activation=self.hidden_activation,\r\n",
    "                    use_bias=False,\r\n",
    "                    kernel_initializer=self.hidden_initializer)\r\n",
    "            if self.center:\r\n",
    "                self.beta_dense = tf.keras.layers.Dense(\r\n",
    "                    units=shape[0], use_bias=False, kernel_initializer='zeros')\r\n",
    "            if self.scale:\r\n",
    "                self.gamma_dense = tf.keras.layers.Dense(\r\n",
    "                    units=shape[0], use_bias=False, kernel_initializer='zeros')\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        \"\"\"如果是条件Layer Norm，则默认以list为输入，第二个是condition\r\n",
    "        \"\"\"\r\n",
    "        if self.conditional:\r\n",
    "            inputs, cond = inputs\r\n",
    "            if self.hidden_units is not None:\r\n",
    "                cond = self.hidden_dense(cond)\r\n",
    "            for _ in range(K.ndim(inputs) - K.ndim(cond)):\r\n",
    "                cond = K.expand_dims(cond, 1)\r\n",
    "            if self.center:\r\n",
    "                beta = self.beta_dense(cond) + self.beta\r\n",
    "            if self.scale:\r\n",
    "                gamma = self.gamma_dense(cond) + self.gamma\r\n",
    "        else:\r\n",
    "            if self.center:\r\n",
    "                beta = self.beta\r\n",
    "            if self.scale:\r\n",
    "                gamma = self.gamma\r\n",
    "        outputs = inputs\r\n",
    "        if self.center:\r\n",
    "            mean = K.mean(outputs, axis=-1, keepdims=True)\r\n",
    "            outputs = outputs - mean\r\n",
    "        if self.scale:\r\n",
    "            variance = K.mean(K.square(outputs), axis=-1, keepdims=True)\r\n",
    "            std = K.sqrt(variance + self.epsilon)\r\n",
    "            outputs = outputs / std\r\n",
    "            outputs = outputs * gamma\r\n",
    "        if self.center:\r\n",
    "            outputs = outputs + beta\r\n",
    "        return outputs\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject(inputs):\r\n",
    "    \"\"\"根据subject_ids从output中取出subject的向量表征\r\n",
    "    \"\"\"\r\n",
    "    output, subject_ids = inputs\r\n",
    "    start = tf.gather(output,subject_ids[:,0],axis=1,batch_dims=1)\r\n",
    "    end = tf.gather(output,subject_ids[:,1],axis=1,batch_dims=1)\r\n",
    "    subject = tf.keras.layers.Concatenate(axis=1)([start, end])\r\n",
    "    return subject\r\n",
    "'''\r\n",
    "   output.shape = (None,128,768)\r\n",
    "   subjudec_ids.shape = (None,2)\r\n",
    "   start.shape = (None,None,768)\r\n",
    "   subject.shape = (None,None,1536)\r\n",
    "   subject[:,0].shape = (None,1536)\r\n",
    "   这一部分给出各个变量的shape应该一目了然\r\n",
    "'''\r\n",
    "   \r\n",
    "def build_model_2(pretrained_path, MAX_LEN, p2id):\r\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\r\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\r\n",
    "    s_po_index =  tf.keras.layers.Input((2,), dtype=tf.int32)\r\n",
    "    \r\n",
    "    bert_model = TFBertModel.from_pretrained(pretrained_path, output_hidden_states=True)\r\n",
    "    outputs = bert_model(ids, attention_mask=att)\r\n",
    "    x, _, hidden_states  = outputs[:3]\r\n",
    "    layer_1 = hidden_states[-1]\r\n",
    "    start_logits = tf.keras.layers.Dense(1,activation = 'sigmoid')(layer_1)\r\n",
    "    start_logits = tf.keras.layers.Lambda(lambda x: x**2)(start_logits)\r\n",
    "    \r\n",
    "    end_logits = tf.keras.layers.Dense(1,activation = 'sigmoid')(layer_1)\r\n",
    "    end_logits = tf.keras.layers.Lambda(lambda x: x**2)(end_logits)\r\n",
    "    \r\n",
    "    subject_1 = extract_subject([layer_1,s_po_index])\r\n",
    "    Normalization_1 = LayerNormalization(conditional=True)([layer_1, subject_1])\r\n",
    "    \r\n",
    "    op_out_put_start = tf.keras.layers.Dense(len(p2id),activation = 'sigmoid')(Normalization_1)\r\n",
    "    op_out_put_start = tf.keras.layers.Lambda(lambda x: x**4)(op_out_put_start)\r\n",
    "    \r\n",
    "    op_out_put_end = tf.keras.layers.Dense(len(p2id),activation = 'sigmoid')(Normalization_1)\r\n",
    "    op_out_put_end = tf.keras.layers.Lambda(lambda x: x**4)(op_out_put_end)\r\n",
    "    \r\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, s_po_index], outputs=[start_logits, end_logits, op_out_put_start, op_out_put_end])\r\n",
    "    model_2 = tf.keras.models.Model(inputs=[ids, att], outputs=[start_logits,end_logits])\r\n",
    "    model_3 = tf.keras.models.Model(inputs=[ids, att, s_po_index], outputs=[op_out_put_start, op_out_put_end])\r\n",
    "    return model, model_2, model_3\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rematch_text_word(tokenizer,text,enc_context,enc_start,enc_end):\r\n",
    "    span = [a.span()[0] for a in re.finditer(' ', text)]\r\n",
    "    decode_list = [tokenizer.decode([i]) for i in enc_context][1:]\r\n",
    "    start = 0\r\n",
    "    end = 0\r\n",
    "    len_start = 0\r\n",
    "    for i in range(len(decode_list)):\r\n",
    "        if i ==  enc_start - 1:\r\n",
    "            start = len_start\r\n",
    "        j = decode_list[i]\r\n",
    "        if '#' in j and len(j)>1:\r\n",
    "            j = j.replace('#','')\r\n",
    "        if j == '[UNK]':\r\n",
    "            j = '。'\r\n",
    "        len_start += len(j)\r\n",
    "        if i == enc_end - 1:\r\n",
    "            end = len_start\r\n",
    "            break\r\n",
    "    for span_index in span:\r\n",
    "        if start >= span_index:\r\n",
    "            start += 1\r\n",
    "            end += 1\r\n",
    "        if end > span_index and span_index>start:\r\n",
    "            end += 1\r\n",
    "    return text[start:end]\r\n",
    "\r\n",
    "\r\n",
    "class Metrics(tf.keras.callbacks.Callback):\r\n",
    "    def __init__(self,model_2, model_3, id2tag, va_text_list, va_spo_list, va_input_ids, va_attention_mask, tokenizer):\r\n",
    "        super(Metrics, self).__init__()\r\n",
    "        self.model_2 = model_2\r\n",
    "        self.model_3 = model_3\r\n",
    "        self.id2tag = id2tag\r\n",
    "        self.va_input_ids = va_input_ids\r\n",
    "        self.va_attention_mask = va_attention_mask\r\n",
    "        self.va_spo_list = va_spo_list\r\n",
    "        self.va_text_list = va_text_list\r\n",
    "        self.tokenizer = tokenizer\r\n",
    "        \r\n",
    "    def on_train_begin(self, logs=None):\r\n",
    "        self.val_f1s = []\r\n",
    "        self.best_val_f1 = 0\r\n",
    "    \r\n",
    "    def get_same_element_index(self,ob_list):\r\n",
    "        return [i for (i, v) in enumerate(ob_list) if v == 1]\r\n",
    "    \r\n",
    "    def evaluate_data(self):\r\n",
    "        Y1 = self.model_2.predict([self.va_input_ids,self.va_attention_mask])\r\n",
    "        question=[]\r\n",
    "        answer=[]\r\n",
    "        for m in range(len(Y1[0])):\r\n",
    "            for z in self.va_spo_list[m]:\r\n",
    "                question.append((z['subject'],z['predicate'],z['object']))\r\n",
    "            start = np.where(Y1[0][m]>0.5)[0]\r\n",
    "            end = np.where(Y1[1][m]>0.5)[0]\r\n",
    "            subjects = []\r\n",
    "            for i in start:\r\n",
    "                j = end[end >= i]\r\n",
    "                if len(j) > 0:\r\n",
    "                    j = j[0]\r\n",
    "                    subjects.append((i, j))\r\n",
    "            if subjects:\r\n",
    "                token_ids_2 = np.repeat([self.va_input_ids[m]], len(subjects), 0)\r\n",
    "                attention_mask_2 = np.repeat([self.va_attention_mask[m]], len(subjects), 0)\r\n",
    "                subjects = np.array(subjects)\r\n",
    "                object_preds_start,object_preds_end = self.model_3.predict([token_ids_2, attention_mask_2, subjects])\r\n",
    "                for subject,object_start,object_end in zip(subjects,object_preds_start,object_preds_end):\r\n",
    "                    sub = rematch_text_word(self.tokenizer,self.va_text_list[m],self.va_input_ids[m],subject[0],subject[1])\r\n",
    "                    start = np.argwhere(object_start > 0.5)\r\n",
    "                    end = np.argwhere(object_end > 0.5)\r\n",
    "                    for _start, predicate1 in start:\r\n",
    "                        for _end, predicate2 in end:\r\n",
    "                            if _start <= _end and predicate1 == predicate2:\r\n",
    "                                ans = rematch_text_word(self.tokenizer,self.va_text_list[m],self.va_input_ids[m],_start,_end)\r\n",
    "                                answer.append((sub,self.id2tag[predicate1],ans))\r\n",
    "                                break\r\n",
    "        Q = set(question)\r\n",
    "        S = set(answer)\r\n",
    "        f1 = 2*len(Q&S)/(len(Q)+len(S))\r\n",
    "        return f1\r\n",
    "    \r\n",
    "    def on_epoch_end(self, epoch, logs=None):\r\n",
    "        logs = logs or {}\r\n",
    "        _val_f1 = self.evaluate_data()\r\n",
    "        self.val_f1s.append(_val_f1)\r\n",
    "        logs['val_f1'] = _val_f1\r\n",
    "        if _val_f1 > self.best_val_f1:\r\n",
    "            self.model.save_weights('../model_dirs/fine_tune_relation_extraction/09_f1={}_model.hdf5'.format(round(_val_f1,4)))\r\n",
    "            self.best_val_f1 = _val_f1\r\n",
    "            print(\"best f1: {} \\n\".format(self.best_val_f1))\r\n",
    "        else:\r\n",
    "            print(\"val f1: {}, but not the best f1 \\n\".format(_val_f1))\r\n",
    "        return      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../model_dirs/bert-base-chinese were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../model_dirs/bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4769c4d750>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4769c4d750>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[4,12,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/tf_bert_model/bert/encoder/layer_._10/attention/self/MatMul (defined at /home/nan/miniconda3/envs/py3.7/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py:259) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_29860]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/tf_bert_model/bert/encoder/layer_._10/attention/self/MatMul:\n model/tf_bert_model/bert/encoder/layer_._10/attention/self/transpose (defined at /home/nan/miniconda3/envs/py3.7/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py:239)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a73449653c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 'lambda_3': new_loss},optimizer=optimizer)\n\u001b[1;32m     12\u001b[0m model.fit([input_ids, attention_mask, send_s_po], [start_tokens, end_tokens, object_start_tokens, object_end_tokens], \\\n\u001b[0;32m---> 13\u001b[0;31m         epochs=20, batch_size=4, callbacks=[Metrics(model_2, model_3 ,id2p, dev_text, dev_spo, val_input_ids, val_attention_mask, tokenizer)])\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mh5_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../model_dirs/fine_tune_relation_extraction/tf_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[4,12,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/tf_bert_model/bert/encoder/layer_._10/attention/self/MatMul (defined at /home/nan/miniconda3/envs/py3.7/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py:259) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_29860]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/tf_bert_model/bert/encoder/layer_._10/attention/self/MatMul:\n model/tf_bert_model/bert/encoder/layer_._10/attention/self/transpose (defined at /home/nan/miniconda3/envs/py3.7/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py:239)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = '../model_dirs/bert-base-chinese'\n",
    "MAX_LEN = max_length\n",
    "# config = BertConfig.from_json_file('../model_dirs/bert-base-chinese/config.json')\n",
    "# TFBertModel.from_pretrained(pretrained_path, config=config)\n",
    "K.clear_session()\n",
    "model,model_2,model_3 = build_model_2(pretrained_path,  MAX_LEN, p2id)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(loss={'lambda': new_loss,\n",
    "                'lambda_1': new_loss,\n",
    "                'lambda_2': new_loss,\n",
    "                'lambda_3': new_loss},optimizer=optimizer)\n",
    "model.fit([input_ids, attention_mask, send_s_po], [start_tokens, end_tokens, object_start_tokens, object_end_tokens], \\\n",
    "        epochs=20, batch_size=2, callbacks=[Metrics(model_2, model_3 ,id2p, dev_text, dev_spo, val_input_ids, val_attention_mask, tokenizer)])\n",
    "\n",
    "h5_path = '../model_dirs/fine_tune_relation_extraction/tf_model.h5'\n",
    "model.save_weights(h5_path)\n",
    "checkpoint_path = '../model_dirs/fine_tune_relation_extraction/checkpoints/my_checkpoint'\n",
    "model.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = '../model_dirs/bert-base-chinese'\r\n",
    "checkpoint_path = '../model_dirs/fine_tune_relation_extraction/checkpoints/my_checkpoint'\r\n",
    "h5_path = '../model_dirs/fine_tune_relation_extraction/tf_model.h5'\r\n",
    "MAX_LEN = max_length\r\n",
    "model,model_2,model_3 = build_model_2(pretrained_path, MAX_LEN, p2id)\r\n",
    "model.load_weights(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\r\n",
    "x1 = [input_ids[[idx]], attention_mask[[idx]]]\r\n",
    "sub_start_tokens, sub_end_tokens = model_2.predict(x1)\r\n",
    "train_spo[idx], p2id[train_spo[idx][0]['predicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_start_idx = int(np.argwhere(sub_start_tokens[0,:,0] > 0.5)[0])\r\n",
    "sub_end_idx = int(np.argwhere(sub_end_tokens[0,:,0] > 0.5)[0])\r\n",
    "sub_text = tokenizer.decode(input_ids[idx][sub_start_idx:sub_end_idx+1]).replace(' ','')\r\n",
    "sub_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [input_ids[[idx]], attention_mask[[idx]], send_s_po[[idx]]]\r\n",
    "obj_start_tokens, obj_end_tokens = model_3.predict(x2)\r\n",
    "obj_start_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_start_idx = np.argwhere(obj_start_tokens[0] > 0.5)\r\n",
    "obj_end_idx = np.argwhere(obj_end_tokens[0] > 0.5)\r\n",
    "for _start, predicate1 in obj_start_idx:\r\n",
    "    for _end, predicate2 in obj_end_idx:\r\n",
    "        if _start <= _end and predicate1 == predicate2:\r\n",
    "            print(_start, _end, predicate1)\r\n",
    "            obj_text = tokenizer.decode(input_ids[idx][_start:_end+1]).replace(' ','')\r\n",
    "            print(obj_text, id2p[predicate1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "pid = os.getpid()\r\n",
    "!kill -9 $pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:316184)",
      "at w.execute (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:315573)",
      "at w.start (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:311378)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325786)",
      "at async t.CellExecutionQueue.start (/home/nan/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325326)"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('py3.7': conda)",
   "name": "python3710jvsc74a57bd001be8e6ef3397cb3b7216ce72275f144d49556b9a40c469805dd9c056d34699f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
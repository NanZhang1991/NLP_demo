{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\r\n",
    "from keras_bert import Tokenizer\r\n",
    "import numpy as np\r\n",
    "import codecs\r\n",
    "import json\r\n",
    "import unicodedata\r\n",
    "\r\n",
    "BERT_MAX_LEN = 512\r\n",
    "\r\n",
    "class HBTokenizer(Tokenizer):\r\n",
    "    def _tokenize(self, text):\r\n",
    "        if not self._cased:\r\n",
    "            text = unicodedata.normalize('NFD', text)\r\n",
    "            text = ''.join([ch for ch in text if unicodedata.category(ch) != 'Mn'])\r\n",
    "            text = text.lower()\r\n",
    "        spaced = ''\r\n",
    "        for ch in text:\r\n",
    "            if ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                spaced += ch\r\n",
    "        tokens = []\r\n",
    "        for word in spaced.strip().split():\r\n",
    "            tokens += self._word_piece_tokenize(word)\r\n",
    "            tokens.append('[unused1]')\r\n",
    "        return tokens\r\n",
    "\r\n",
    "def get_tokenizer(vocab_path):\r\n",
    "    token_dict = {}\r\n",
    "    with codecs.open(vocab_path, 'r', 'utf8') as reader:\r\n",
    "        for line in reader:\r\n",
    "            token = line.strip()\r\n",
    "            token_dict[token] = len(token_dict)\r\n",
    "    return HBTokenizer(token_dict, cased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vocab_path = 'vocab.txt'\r\n",
    "tokenizer = get_tokenizer(bert_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([101,\n  4263,\n  15605,\n  14347,\n  13356,\n  15282,\n  17963,\n  13356,\n  14869,\n  15266,\n  14355,\n  19889,\n  16229,\n  21077,\n  8818,\n  9219,\n  13329,\n  21078,\n  21080,\n  16278,\n  13728,\n  13912,\n  19773,\n  20827,\n  14429,\n  16357,\n  8740,\n  14119,\n  14203,\n  14577,\n  13897,\n  16740,\n  13819,\n  17568,\n  15151,\n  21080,\n  13917,\n  20085,\n  8311,\n  14119,\n  16222,\n  21080,\n  14429,\n  16740,\n  20447,\n  19773,\n  19178,\n  16387,\n  20827,\n  13728,\n  13820,\n  21080,\n  9546,\n  15456,\n  18872,\n  14452,\n  15282,\n  16229,\n  13743,\n  17575,\n  18336,\n  15554,\n  16690,\n  15523,\n  19428,\n  19452,\n  21080,\n  15825,\n  13768,\n  14116,\n  17470,\n  15553,\n  13848,\n  16354,\n  17822,\n  17695,\n  15825,\n  15456,\n  17568,\n  13839,\n  1,\n  102],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('爱德华·尼科·埃尔南迪斯（1986-），是一位身高只有70公分哥伦比亚男子，体重10公斤，只比随身行李高一些，2010年获吉尼斯世界纪录正式认证，成为全球当今最矮的成年男人')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n '爱',\n '##德',\n '##华',\n '##·',\n '##尼',\n '##科',\n '##·',\n '##埃',\n '##尔',\n '##南',\n '##迪',\n '##斯',\n '##（',\n '##19',\n '##86',\n '##-',\n '##）',\n '##，',\n '##是',\n '##一',\n '##位',\n '##身',\n '##高',\n '##只',\n '##有',\n '##70',\n '##公',\n '##分',\n '##哥',\n '##伦',\n '##比',\n '##亚',\n '##男',\n '##子',\n '##，',\n '##体',\n '##重',\n '##10',\n '##公',\n '##斤',\n '##，',\n '##只',\n '##比',\n '##随',\n '##身',\n '##行',\n '##李',\n '##高',\n '##一',\n '##些',\n '##，',\n '##2010',\n '##年',\n '##获',\n '##吉',\n '##尼',\n '##斯',\n '##世',\n '##界',\n '##纪',\n '##录',\n '##正',\n '##式',\n '##认',\n '##证',\n '##，',\n '##成',\n '##为',\n '##全',\n '##球',\n '##当',\n '##今',\n '##最',\n '##矮',\n '##的',\n '##成',\n '##年',\n '##男',\n '##人',\n '[unused1]',\n '[SEP]']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('爱德华·尼科·埃尔南迪斯（1986-），是一位身高只有70公分哥伦比亚男子，体重10公斤，只比随身行李高一些，2010年获吉尼斯世界纪录正式认证，成为全球当今最矮的成年男人')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ������ D �еľ��� D\n",
      " �������к��� C26C-E5B8\n",
      "\n",
      " d:\\Documents\\project\\demo\\tf_practice ��Ŀ¼\n",
      "\n",
      "2021/06/08  16:17    <DIR>          .\n",
      "2021/06/08  16:17    <DIR>          ..\n",
      "2021/06/03  11:36            35,844 1.ipynb\n",
      "2021/06/03  11:36            27,120 2.ipynb\n",
      "2021/06/08  16:38             3,773 3.ipynb\n",
      "2021/06/03  11:36             2,243 keras_layers.ipynb\n",
      "               4 ���ļ�         68,980 �ֽ�\n",
      "               2 ��Ŀ¼ 172,839,354,368 �����ֽ�\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('KB': conda)",
   "name": "python3710jvsc74a57bd083b5b3efe3a9978372deb74d899f5f21fa77216f13b11d502345dddf3bb4d657"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
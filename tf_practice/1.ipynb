{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Requirement already satisfied: tensorflow in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/miniconda3/envs/tfs/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_7028/551868434.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 08:41:12.987164: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-07 08:41:13.011378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.095199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.095642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.934428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.934849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.934876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-12-07 08:41:13.935230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.935300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 2753 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2021-12-07 08:41:13.938000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.938361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-07 08:41:13.941104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 08:08:47.054262: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-20 08:08:47.055016: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-08-20 08:08:47.055417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2021-08-20 08:08:47.055465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-20 08:08:47.055496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-20 08:08:47.055510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-20 08:08:47.055522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-20 08:08:47.055535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-20 08:08:47.055547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-20 08:08:47.055559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-20 08:08:47.055572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-20 08:08:47.056000: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-08-20 08:08:47.056828: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-08-20 08:08:47.057251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-20 08:08:47.057309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-20 08:08:47.057318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-08-20 08:08:47.057324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-08-20 08:08:47.058847: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-08-20 08:08:47.059187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1489] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-08-20 08:08:47.060030: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-08-20 08:08:47.060565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2967 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "# 实际的线\n",
    "TRUE_W = 3.0\n",
    "TRUE_B = 2.0\n",
    "\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "# 随机向量x\n",
    "x = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "# 生成噪声\n",
    "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "# 计算y\n",
    "y = x * TRUE_W + TRUE_B + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb5ElEQVR4nO3df4xlZXkH8O93ZmeKdxcie3erCOwdUtEEqFKZEBsbY0Etbo1EEwnmLq5Asi5Isk1MGukkrY2ZxMSmlrQuMG3BZfdWY9IaiW6rQG1MDFZnLeoCUondGSAo+0Pj/gBnd+bpH+89zJk755x77o9zzznv+X6Sm9n7Y859V9nnvvd5n/d5aWYQERE/jeU9ABERyY6CvIiIxxTkRUQ8piAvIuIxBXkREY9tyHsAYVu2bLGpqam8hyEiUiqHDh06ZmZbo54rVJCfmprC/Px83sMQESkVkgtxzyldIyLiMQV5ERGPKciLiHhMQV5ExGMK8iIiHlOQFxHJUasFTE0BY2PuZ6s13OsXqoRSRKRKWi1g1y7gzBl3f2HB3QeAZnM476GZvIhITmZmVgN84MwZ9/iwKMiLiORkcbG3x/uhIC8ikpNt23p7vB8K8iIiOZmdBWq1tY/Vau7xYVGQFxHJSbMJzM0BjQZAup9zc8NbdAVUXSMikqtmc7hBvZNm8iIiHlOQFxHxmIK8iIjHFORFRDymIC8i4jEFeRERjynIi4gg+26QeVGdvIhU3ii6QeZFM3kRqbxRdIPMi4K8iFTeKLpB5kVBXkS80W9efRTdIPOiIC8iXgjy6gsLgNlqXj1NoB9FN8i8KMiLiBf6yasHM/9bbgFe8xqgXs+uG2ReFORFpFTiUjJp8+rB75MuuAcz/+PHgZdfBvbvB44cca/1oaRSJZQiUhpJpY7btrn7ncJ59c7fN1v72vDM35eSSlrn3zJH09PTNj8/n/cwRKSgpqaiA/n4OLC87Gbn4ZBWq61Nu8T9fhgZ/4HRaKzO8ouE5CEzm456TukaESmNuJTM8rL7aeaCNBCdV09TErltm18llQryIjJywy51DDNbnXF3pla6/f7EhKuo8amkUkFeREZq2KWOUeJm3N1+/4IL3AeDTyWVCvIiMlKDtBDoPPh6fDz6dXEz7uD345w4Ef0+ZS6p1MKriIzU2Nj6qhbABdOVld6u1VktA6xfbI0StwBb1IXVbjJfeCX5AMmXSB4OPbaZ5CMkf9b+eeEw3ktEyinIw8fNK/vJd/c74/YpHdPNsNI1XwRwQ8djnwLwmJldDuCx9n0RqaBwHj7KIAG22XSz75WV6MXWuN/xJR3TzdDSNSSnAHzdzK5q338GwLvM7EWSFwH4LzN7c9I1lK4R8VNSfXqj4QK8jwF2VJLSNVnueH2dmb3Y/vMvALwuw/cSkQKLq3Yhy5kDL5ORVNeY+7oQ+ZWB5C6S8yTnjx49OorhiMiI+VR3XjZZBvlfttM0aP98KepFZjZnZtNmNr1169YMhyMieRnVQqev57QOIssg/zCAne0/7wTwtQzfS0QKbBQLnYNssvLZsEoovwTgcQBvJvk8ydsBfBbAe0j+DMC72/dFxGNJM+mkKphhzMB9Pqd1EENZeDWzj8Q8df0wri8ixZfUBjhpxt7v73XyqanYMKmtgYgMRb8z6T17Bp+Bt1ruW0CUqi/uKsiLyFDEzZgXFlwK5s4716dkWi13IlMv1+sUfBMI2g13OnWq2nl59a4RkaFIcyBHWK3mzlWNC/Jp+8iked80/WzKTIeGiEjm0rYBDpw5Ex/gg+ulkWbGX+UFWAV5EelLZ0UMsFomOah6Pf2sO23OvaoLsAryItKzuJp0wKVY6vV016nXozdJ3XNP+rGk/QZR1QVYBXkR6dmwatLvuae3TVJR9fTBRqu4A0QAf9sIp2Jmhbldc801JiKjdeCAWaNhRrqfBw50/x3SzM3h195I9/tRz3XexsZ6e88DB8xqtbXXqNVWfzfqecCsXk93/TIDMG8xcTX3wB6+KciLjFa3wBmn0YgO3PV6dKDtdhvkPRuNtX+fXj+wfJAU5JWuEamwuLTLjh3r2wsEqRIyehEzyIt3Xi+NcKonrsVBmh2t/Rwg4jsFeREPpe0Fk1RxEm7w1Xmyk3Vsr6nXXV48OAi7H4uL0Qu6O3YAW7YAmzdH/15VF1TT0mYoEc/0crh1mo1EQUlk0uuCjUu9bojq5X3GxoANG4ClpdXHfN/klJY2Q4lUSC+VL2nKDxcXu9eYLyy4NM5zzyVXuQTItfeD6pek91lZASYmqnEu6zApyIt4plsPmc72vzt3Rr8+sG1b+pTIykp8D5mw666LDtbd3uf0afdhoJx7egryIp5JCpSdB2m0Wi7AJllYcE2+JieHN8bHH48O1mm+WeggkN4oyIt4plugDFI3rRZw663pZt7Hj7uF0GAna1xb37Ti0kfBxqak61e5D00/FORFSixpB2hSD5nFReDjHwfOnk3/XmfPuuqZTZvcDHxQcWmlZhN46KHkbw5V7UPTDwV5kZJKOtM0qBePC/Sky2/3ysylboZh8+bkowIfeCB+EVdlk+kpyIuUVJoqmtnZ6BnxMGbig5icBH7zm+RDt5tNYN++6AZmle1D0wcFeZGSSrMD9LvfXVtXXgSNBnD++etTRVG59nDqSWWT/VGQFymBqNx7XMoieLzVAu67b1QjTCfYNBW3Mzbqg0utCgajIC9SAEltCOJy79u3J6cyZmbWtx/IE7laq68WBaOjIC+Ss6QFVCA+937//W4jU1wqo0gVKOTqB87CAnDypNu9GqZcezbUu0YkZ3H9XoLUxthY8oy8XneHb/TTlyZP9borx1xcdDP42VmlYvql3jUiBZbUhiAp9x44fhy45RbgyitdAy/S/dy4cfhjHaYTJ5RrHwUFeZERSMq5JwXxXbuAN76x+/XNgKeeWt29urzs7heZ8u+joSAvkrFuOfekNgRnzgCPPTa6sY6K8u+joyAvkrFum5aCWnDfjY+r1j0PCvIiGUt7bF3Q/MtHExNu96ry76OnIC+SsW6blsqm88CPiQn3AUXG95q54AIF9rwoyItkLCrnPjnpGn2FF2IHOR91VEhg9+61tfkPPggcO+Zm6XE9ccrwd/PVhrwHIOK7YAY7M+NSNJs3u+Zcx4+7xxcWXAnkxo3D6/CYld27gb1745/fvHn179X5uOQj85k8ySMkf0LyCZLa6SSVFO6/smnT+uZcw2zhm5U77kgO8FJMo0rX/LGZXR23I0ukCoJa+SLvQo1Cpg/wcWkZpWvyo5y8yAjceSewY0f5Ajzg1hPe8Y50r/VtkdkHowjyBuBbJA+R3NX5JMldJOdJzh89enQEwxEZrVYLuPfevEfRv9On0x+eHbXIrI1P+RpFkP8jM3sbgPcB+ATJd4afNLM5M5s2s+mtW7eOYDgig0lqURD1/J49ox/jsKU9PFuHfBTPSLtQkvw0gFNm9jdRz6sLpRRd0KIgvIM1KCvcuzf6eV+Q+R8bKNFy60JJciPJ84M/A3gvgMNZvqdIlqJaFJi5E5harejnfaEyyHLKuk7+dQC+SrdFbgOAfzGz/8j4PUUyE9eiwAz46EfLO9Mda0/3yjp+iZfpTN7Mfm5mb23frjQzLb9IqXTm15Nms2UOkBdeCDz0UHw3TEBlkGWlEkqRGFEtgk+ezHtU2Qh2qc7NxfefURlkOSnIi8SIyq8vLeUzllHY1S5w3rdPZZA+UZCXyupWClmkg7BHISiTVBmkX3SQt1RSVKljrQbs3AkcPOgC/NjY6nF6VaEyyXJKKqFUF0qppLjTmu67z+XfAb8CfNADvtsHl/Lu/lG6RiopqRSy05gH/0omJoD9+6Pz7QHl3f3kwX++Ir3rZcbqQ/piaWl9vh1YraRR3t1fCvJSSVGNtDqPtfNN8O0l6G1vBpw7537q3FV/KchLJUVVkOzenbwZqOyUb68mBXmphKhyyfBpTUeOuAZjO3fGbwYqi4kJd4ZsmPLt1aUgL96L2rka1R+91XILk2WuqhkfdwdrP/CA6tzFUZAX78WVS+7cuXZmn6aD5MaNmQ1zYJOT7sNrZsYdDA64ihrl26tNm6HEe2Nj0aWRYeRwXpOnsTFgw4a1rRdqNc3iqyC3fvIiRZBmwTFN8C5ygAfc2kJnb520JzqJvxTkxXtR5ZJVUrUePLKWgrx4LZxrL3vVTL9UOllt6l0j3upsQlbmqpk0xsej/47bt49+LFIcmsmLt/bs8e+81c5ducH9RgN47Wujf+fgwUyHJAWnIC+lFdcPvtUCtmxZPe2o7Op14MABt/C7f//a+vf9+1fbEsQdz6ecfLWphFJKKaoffFDiWPRSx140Gi6ApzE15TZ6DXINKSeVUIp3ojYuBYHdlwAPRAftOFFVRGpnIAryUhrh9Ewvwa/Mxse7H1MY0LF9EkXpGimFVgu49Vbg7Nm8RzK4XtNJtdr6YwoVvCVM6RopvT17/AjwgOt/k/a0qfHx6L472sUqaSnISyn4UikDAKdOuR4z3Zqd1Wrxtf2qmJG0FOSlcIISSNLdNm3Ke0TDt7QEvPJK/PPj42uP6eukXaySloK8jETaxcNWC/jYx9bO3E+fHsEAcxA3S6/VXF/7ZlMVMzI4BXnJXNpDOwCXez93bvRjLIrOihhVzMigVF0jmUuzSSdoJFaV0sgopGsXLNKrpOoaNSiTzMUtEgYBPWr3ahUpzy5ZULpGMhcXvMj0x+75Tnl2yYqCvGRudnZ990TA5ednZqpbDjg+rjy7ZC/zIE/yBpLPkHyW5Keyfj8pnmYzfofnwkL6jUG+WVlxNx20LVnK9J8XyXEAXwDwPgBXAPgIySuyfE8pjnDZZNypTGT5D/Oo1/v7PeXgZRSynkNdC+BZM/u5mS0B+DKAGzN+TymAzrLJuEBeoOKuvt10U+9nyCoHL6OSdZC/GMBzofvPtx97FcldJOdJzh89ejTj4cioVGkx9eDB9bXsd9yxPvCHT3FSDl5GJfdsqJnNmdm0mU1v3bo17+HIkFRpMXVx0QXsI0dWc+x7964P/OFTnBTgZVSyrpN/AcClofuXtB8Tz23bVp2NTXG59WZTwVzyl/VM/gcALid5GclJADcDeDjj95SchBdaT50CJifzHlH2SOXWpdgyDfJmdg7AXQC+CeBpAF8xsyezfE/JR+dC6/Hj7me97gJhvQ5MTOQ9yuEigd27NVuXYss8J29mB83sTWb2e2amOY+nohZaz54Ffv1r9+dNm4B3vjN6U1SZBB9aQY597968RySSTL1rZCjiFlqD0smFBfeaMpdMbtwIHDuW9yhEepN7dY34Ic3GnjIHeAA477y8RyDSOwV56SpYUA1OaiLd8XV33rn6XBUqaU6cyHsEIr1TukYSxbUBXl4G7r0XuP/+6vRAVxsCKSPN5CVRt52rvQT4ycnyLryqDYGUlYK8JBrmztWlpXLm5dWGQMpMQV4SDZqiKOvMHXCz9wMH1IZAyk1BXhLNzvbeYTFAlnPmHtDsXXygIC+Jmk0X7JJs2hT9eJkDfKOhAC9+UJCXrprN5IMxXn55dGMZBS2yik8U5KWrVgv41a/iny/jyU5Bz/dGw90PTq7SIqv4RnXykiiok/epFp50i6kiVaCZvCQq4glPExODtTHWpiapEgV5SVS0dgUbNwIPPgjcfvtqimV8HLj++tVTmJIo3y5VoyAvsVqt4tW5b9nifu7bt7oWsLwMPP64C94rK6t59k7j48q3S/UoJy+RWi1g587ilUEuLkankM6ccY8D7lSqTrWaArxUk2byFRQ+pm9qyt3vfH7XrmJWzZjFp5AWFty4jx9f+3i9rgAv1aWZfMV0dpUMAiOwGgSLuNiaxvh49Lg3bVKAl+rSTN4z3Wbp3VIdQPEWW9Oo1eK/eQyzyZpI2SjIe6TzMO1glh4O9HEBL/x4ULVSBsF5q3Nz8QuuKpmUKlOQL6moGXuaWXpcwAs/npSLH6Q+fdgaDVdNE3SJjGqmppJJqToF+RKKm7HHpVnCs/Q0gTBuRgwA5865WnXSLWiOZfRfEJn8gRIVvINmakG9vFoUiCjIl1LcjD0uzRKepYcDIbC6WDkzs5rW2b49vj5+ZQU4fRrYvRs4dgx46KHo5mUbBljSJ931z56Nf01c8G423cw+PMMXqTJagQqhp6enbX5+Pu9hFN7YWHz9eq229gMgrj486uxWErjuOrexqFt1zfi4m9WHr7dnz2r54tjYYP1ugg+hqG8njYZ6z4iEkTxkZtNRz2kmX0JxefXwAmRSuiLY6NQZyM2Axx5LVz65vLy+cifccnjQhmaLi8qxiwyFmRXmds0115h0d+CAWa1m5sKyu9Vq7vF+frffW/g9G43hXDO4NRqr4200zEj3M83fUaRqAMxbTFzVTL6Eui0wJtXKD3Oj05kz7htBqzXcWvTwbF05dpHBKMh7plut/LA3Bi0vA7feCmzePJzrqQWByHApyJdQUiDfsye5Vj6LjUFnzwKvvNJbDX29vrYqp14HDhxwFTsK8CLDo+qaEpqaiq46qdfXN+cKkC7lEVVVMyxJ7x83HhEZnKprPBOXckkKsMEMvjOfP8wWBidOpH+tWg2IjEZmQZ7kp0m+QPKJ9m17Vu9VNf0EyHDZYXgxc1iz6Xo9Pi/fubFKZZAio5P1TP7zZnZ1+3Yw4/eqjLj68aidp4B7PC7PPawZ9U03ASdPrn98YsLtXlWrAZF8qJ98CYX7vi8uukAdzIw78+21GnDPPfHXmp0FbrsNWFoabEwHD0Zf44ILgL17B7u2iPQv6yB/F8mPApgH8Ekz+1XnC0juArALALYpUZtasxk/G+4M/t1mzXFr741G/IdH5+vi1gl6ydOLyPANVF1D8lEAr494agbA9wAcA2AAPgPgIjO7Lel6qq4ZvbhKnc7+MJ29aQJBb5yZGfWZEclLZtU1ZvZuM7sq4vY1M/ulmS2b2QqAfwRw7SDv5ZtuJziNSppDRAD3beDYMVfLHpVfV58ZkWLKsrrmotDdDwI4nNV7lU3UZqYdO1zgJIEtW4Yf9OM+VNIcIhIW12ZAvdxFiimzzVAk9wO4Gi5dcwTAx83sxaTfqUq6Ji5FEjYxATz44HCCZNQGqCDNAsQ/pwAtUg5J6RrteM1BUj/4sGHks4O2wlFH+gXXD44O7GWxVkSKQzteCyZtEVFUvryXXH4wg487szW4fmcKBijGeoGIDE5BPgdRi5RROj8MunWY7NStrXDUh02v7yEixaYgn4POc1ajjI2tr0yJO9s16DDZKamtcFzlS6/vISLFpiCfkyBFEhfoL7xwfV68W7ljZyonrpfM+Hj8wmrakkoRKQcF+Zz1slM0qdwxKs1y8qSr0gmr1YB9+3rvZaPNyCLlpCCfs7jgabZ+0TNpw1FUmmVpyfWO6aV2XZuaRPyiIJ+zpEXYzkXPpA1HSd8IejkjVZuaRPyiIJ+zbouwnYueceWOcXX3/aRZdHi2iD8U5AsgCKqdh2sE4mbp4Tx8FKVZRERBPkdpq2HiZuNJdfBKs4gIoENDctPZT2ZhAZicdNUwZ8+uvi5pNh43wyfV3ldEHM3kczKMahiVO4pIN5rJ5ySpGubYsXTXmJ2N7iCpPLyIBDSTz8kwZuEqdxSRbhTkczKsTUcqdxSRJAryOdEsXERGQTn5HDWbCuoiki3N5EVEPKYgLyLiMQV5ERGPKciLiHhMQV5ExGMK8iIiHlOQFxHxmIK8iIjHFORFRDymIC8i4jEFeRERjynIi4h4TEFeRMRjCvIiIh5TkBcR8dhAQZ7kh0k+SXKF5HTHc3eTfJbkMyT/ZLBhjk6rBUxNAWNj7merlfeIRET6N+ihIYcBfAjA/eEHSV4B4GYAVwJ4A4BHSb7JzJYHfL9MtVprD8ZeWHD3AR3uISLlNNBM3syeNrNnIp66EcCXzey3ZvZ/AJ4FcO0g7zUKMzOrAT5w5ox7XESkjLLKyV8M4LnQ/efbj61DchfJeZLzR48ezWg46Swu9va4iEjRdQ3yJB8leTjiduMwBmBmc2Y2bWbTW7duHcYl+7ZtW2+Pi4gUXdecvJm9u4/rvgDg0tD9S9qPFdrs7NqcPADUau5xEZEyyipd8zCAm0n+DsnLAFwO4PtZvNEwq2GaTWBuDmg0ANL9nJvToquIlNdA1TUkPwjg7wFsBfANkk+Y2Z+Y2ZMkvwLgKQDnAHwii8qaLKphmk0FdRHxB80s7zG8anp62ubn51O/fmrKBfZOjQZw5MjQhiUiUmgkD5nZdNRzpd7xqmoYEZFkpQ7yqoYREUlW6iA/O+uqX8JUDSMisqrUQV7VMCIiyQbtXZM7VcOIiMQr9UxeRESSKciLiHhMQV5ExGMK8iIiHlOQFxHxWKHaGpA8CiCiUcHAtgA4lsF1B6Vx9Ubj6o3G1Zsyj6thZpG92gsV5LNCcj6ur0OeNK7eaFy90bh64+u4lK4REfGYgryIiMeqEuTn8h5ADI2rNxpXbzSu3ng5rkrk5EVEqqoqM3kRkUpSkBcR8VilgjzJT5I0klvyHgsAkPwMyR+TfILkt0i+Ie8xAQDJz5H8aXtsXyX52rzHBAAkP0zySZIrJHMvdSN5A8lnSD5L8lN5jydA8gGSL5E8nPdYAiQvJfltkk+1/z/ck/eYAIDkeSS/T/JH7XH9dd5jCiM5TvJ/SH6932tUJsiTvBTAewEU6XDAz5nZW8zsagBfB/CXOY8n8AiAq8zsLQD+F8DdOY8ncBjAhwB8J++BkBwH8AUA7wNwBYCPkLwi31G96osAbsh7EB3OAfikmV0B4O0APlGQ/71+C+A6M3srgKsB3EDy7fkOaY09AJ4e5AKVCfIAPg/gzwEUZqXZzH4TursRBRmbmX3LzM61734PwCV5jidgZk+b2TN5j6PtWgDPmtnPzWwJwJcB3JjzmAAAZvYdACfyHkeYmb1oZj9s//kkXOC6ON9RAeacat+daN8K8e+Q5CUA/hTAPw1ynUoEeZI3AnjBzH6U91g6kZwl+RyAJoozkw+7DcC/5z2IAroYwHOh+8+jAEGrDEhOAfgDAP+d81AAvJoSeQLASwAeMbNCjAvA38FNTFcGuUjpT4YKkHwUwOsjnpoB8BdwqZqRSxqXmX3NzGYAzJC8G8BdAP6qCONqv2YG7mt2axRjSjsuKS+SmwD8K4A/6/gmmxszWwZwdXvt6askrzKzXNczSL4fwEtmdojkuwa5ljdB3szeHfU4yd8HcBmAH5EEXOrhhySvNbNf5DWuCC0ABzGiIN9tXCQ/BuD9AK63EW6m6OF/r7y9AODS0P1L2o9JDJITcAG+ZWb/lvd4OpnZr0l+G249I+9F63cA+ADJ7QDOA3AByQNmtqPXC3mfrjGzn5jZ75rZlJlNwX2tftsoAnw3JC8P3b0RwE/zGksYyRvgviZ+wMzO5D2egvoBgMtJXkZyEsDNAB7OeUyFRTfD+mcAT5vZ3+Y9ngDJrUH1GMnXAHgPCvDv0MzuNrNL2jHrZgD/2U+AByoQ5AvusyQPk/wxXDqpEGVlAP4BwPkAHmmXd96X94AAgOQHST4P4A8BfIPkN/MaS3th+i4A34RbRPyKmT2Z13jCSH4JwOMA3kzyeZK35z0muJnpLQCua/839UR7lpq3iwB8u/1v8AdwOfm+yxWLSG0NREQ8ppm8iIjHFORFRDymIC8i4jEFeRERjynIi4h4TEFeRMRjCvIiIh77f8VX4URXjIbuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x, y, c=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 08:10:24.741795: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-20 08:10:24.743187: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 08:10:25.032865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/32 [=======================>......] - ETA: 0s - loss: 1.2199 - mae: 0.9853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 08:10:25.456760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 6ms/step - loss: 1.1743 - mae: 0.9617\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4903 - mae: 0.5735\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2629 - mae: 0.4068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3e94b40750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Construct and compile an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Just use `fit` as usual\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(x, y, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[-0.21265732,  1.4681922 ,  1.3959696 , -0.780908  ],\n",
       "       [-0.21265732,  1.4681922 ,  1.3959696 , -0.780908  ],\n",
       "       [-0.21265732,  1.4681922 ,  1.3959696 , -0.780908  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "# Call model on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name=\"my_sequential\")\n",
    "model.add(layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n",
    "model.add(layers.Dense(4, name=\"layer3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Dense(3)\n",
    "layer.weights  # Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_7/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[-0.87336516, -0.34015906, -0.7433777 ],\n",
       "        [ 0.65673065, -0.2353059 ,  0.3450576 ],\n",
       "        [ 0.8730222 , -0.6765791 ,  0.7184082 ],\n",
       "        [-0.61522204, -0.19517785,  0.41657734]], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call layer on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights  # Now it has weights, of shape (4, 3) and (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 6\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")  # No weights at this stage!\n",
    "\n",
    "# At this point, you can't do this:\n",
    "# model.weights\n",
    "\n",
    "# You also can't do this:\n",
    "# model.summary()\n",
    "\n",
    "# Call the model on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))  # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (1, 2)                    10        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (1, 3)                    9         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, 4)                    16        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用内置方法进行训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.5920 - sparse_categorical_accuracy: 0.8343 - val_loss: 0.1899 - val_sparse_categorical_accuracy: 0.9458\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1785 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.1419 - val_sparse_categorical_accuracy: 0.9611\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3568549156188965, 0.16724228858947754],\n",
       " 'sparse_categorical_accuracy': [0.8980799913406372, 0.9509599804878235],\n",
       " 'val_loss': [0.1898895502090454, 0.14190366864204407],\n",
       " 'val_sparse_categorical_accuracy': [0.9458000063896179, 0.9610999822616577]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为方便以后重用，我们将模型定义和编译步骤放入函数中；我们将在本指南的不同示例中多次调用它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  仅在使用 NumPy 数据进行训练时才能使用 validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.9650 - val_loss: 0.1313 - val_sparse_categorical_accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29e46daa808>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data 数据集进行训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.8518\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.1745 - sparse_categorical_accuracy: 0.9483\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1270 - sparse_categorical_accuracy: 0.9633\n",
      "Evaluate\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.14289292693138123,\n",
       " 'sparse_categorical_accuracy': 0.9535999894142151}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))\n",
    "\n",
    "# 请注意，数据集会在每个周期结束时重置，因此可以在下一个周期重复使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steps_per_epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 请注意，数据集会在每个周期结束时重置，因此可以在下一个周期重复使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 1.1881 - sparse_categorical_accuracy: 0.6777\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3868 - sparse_categorical_accuracy: 0.8914\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.8935\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.2667 - sparse_categorical_accuracy: 0.9222\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.2487 - sparse_categorical_accuracy: 0.9261\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.2273 - sparse_categorical_accuracy: 0.9290\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.2341 - sparse_categorical_accuracy: 0.9274\n",
      "Epoch 8/10\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.2255 - sparse_categorical_accuracy: 0.9330WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2241 - sparse_categorical_accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n如果您只想在来自此数据集的特定数量批次上进行训练，则可以传递 steps_per_epoch 参数，此参数可以指定在继续下一个周期之前，模型应使用此数据集运行多少训练步骤。\\n\\n如果执行此操作，则不会在每个周期结束时重置数据集，而是会继续绘制接下来的批次。数据集最终将用尽数据（除非它是无限循环的数据集）。\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=10, steps_per_epoch=100)\n",
    "'''\n",
    "如果您只想在来自此数据集的特定数量批次上进行训练，则可以传递 steps_per_epoch 参数，此参数可以指定在继续下一个周期之前，模型应使用此数据集运行多少训练步骤。\n",
    "\n",
    "如果执行此操作，则不会在每个周期结束时重置数据集，而是会继续绘制接下来的批次。数据集最终将用尽数据（除非它是无限循环的数据集）。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用验证数据集\n",
    "可以在 fit() 中将 Dataset 实例作为 validation_data 参数传递："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5717 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.1775 - val_sparse_categorical_accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29e55185908>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在每个周期结束时，模型将迭代验证数据集并计算验证损失和验证指标。\n",
    "\n",
    "如果只想对此数据集中的特定数量批次运行验证，则可以传递 **validation_steps 参数**，此参数可以指定在中断验证并进入下一个周期之前，模型应使用验证数据集运行多少验证步骤：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 5ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8478 - val_loss: 0.2873 - val_sparse_categorical_accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29e54bd59c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 如果只想对此数据集中的特定数量批次运行验证，则可以传递 validation_steps 参数，\n",
    "此参数可以指定在中断验证并进入下一个周期之前，模型应使用验证数据集运行多少验证步骤：\n",
    "'''\n",
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b3892a51360d3168d14ce08c6309bdc6f2c9740373118aebbe4c7a897192efa"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
